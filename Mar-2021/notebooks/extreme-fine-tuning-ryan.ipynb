{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "papermill": {
     "duration": 2.138608,
     "end_time": "2021-02-19T02:57:47.964373",
     "exception": false,
     "start_time": "2021-02-19T02:57:45.825765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=[[1,1,1],[3,3,3]]\n",
    "t2=[[1,1,1],[3,3,3]]\n",
    "test_t=[]\n",
    "test_t[len(test_t):] = t1\n",
    "test_t[len(test_t):] = t2\n",
    "np.save(f'test.npy', test_t)\n",
    "test_l = np.load('test.npy')\n",
    "np.array(test_l).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "papermill": {
     "duration": 4.206009,
     "end_time": "2021-02-19T02:57:52.183073",
     "exception": false,
     "start_time": "2021-02-19T02:57:47.977064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('..\\\\kaggle_data\\\\train.csv')\n",
    "test = pd.read_csv('..\\\\kaggle_data\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "papermill": {
     "duration": 0.095898,
     "end_time": "2021-02-19T02:57:52.291780",
     "exception": false,
     "start_time": "2021-02-19T02:57:52.195882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train.target\n",
    "X_test = test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "papermill": {
     "duration": 0.020649,
     "end_time": "2021-02-19T02:57:52.324883",
     "exception": false,
     "start_time": "2021-02-19T02:57:52.304234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cols = [feature for feature in train.columns if 'cat' in feature]\n",
    "\n",
    "def label_encoder(df):\n",
    "    for feature in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "papermill": {
     "duration": 1.818185,
     "end_time": "2021-02-19T02:57:54.155645",
     "exception": false,
     "start_time": "2021-02-19T02:57:52.337460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = label_encoder(X_train)\n",
    "X_test = label_encoder(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list_final_iterations =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = 'N:\\\\kaggle_data\\\\march'\n",
    "\n",
    "def objective(trial, X, y, name='xgb'):\n",
    "            \n",
    "    if trial.number % 5 == 0:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    params = {'max_depth':trial.suggest_int('max_depth', 5, 50),\n",
    "              'n_estimators':200000,\n",
    "              #'boosting':trial.suggest_categorical('boosting', ['gbdt', 'dart', 'goss']),\n",
    "              'subsample': trial.suggest_uniform('subsample', 0.2, 1.0),\n",
    "              'colsample_bytree':trial.suggest_uniform('colsample_bytree', 0.2, 1.0),\n",
    "              'learning_rate':trial.suggest_uniform('learning_rate', 0.007, 0.02),\n",
    "              'reg_lambda':trial.suggest_uniform('reg_lambda', 0.01, 50),\n",
    "              'reg_alpha':trial.suggest_uniform('reg_alpha', 0.01, 50),\n",
    "              'min_child_samples':trial.suggest_int('min_child_samples', 5, 100),\n",
    "              'num_leaves':trial.suggest_int('num_leaves', 10, 200),\n",
    "              'n_jobs' : -1,\n",
    "              'metric':'rmse',\n",
    "              'max_bin':trial.suggest_int('max_bin', 300, 1000),\n",
    "              'cat_smooth':trial.suggest_int('cat_smooth', 5, 100),\n",
    "              'cat_l2':trial.suggest_loguniform('cat_l2', 1e-3, 100)}\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "                  \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    print(f'Fit Starting')\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "              eval_metric=['rmse'],\n",
    "              early_stopping_rounds=250, \n",
    "              categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "              #callbacks=[optuna.integration.LightGBMPruningCallback(trial, metric='rmse')],\n",
    "              verbose=0)\n",
    "    \n",
    "    print(f'Appending to List')\n",
    "    preds_list_final_iterations.append(model.predict(X_test))\n",
    "\n",
    "    dt_string = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "    #np.save(f'..\\\\kaggle_data\\\\{dt_string}_FI{fold_index}_sub.npy', preds_list_final_iterations)\n",
    "    print(f'Calculating Mean')\n",
    "    y_preds_final_iteration = np.array(preds_list_final_iterations).mean(axis=0)\n",
    "    print(f'length of infal list:{len(preds_list_final_iterations)}')\n",
    "    submission = pd.DataFrame({'id':test.id,\n",
    "              'target':y_preds_final_iteration})\n",
    "    file_target = f'{root_directory}\\\\wave5_{dt_string}_AUTOML_sub-40.csv'\n",
    "    submission.to_csv(file_target, index=False)\n",
    "    print(f'written to CSV {file_target}')\n",
    "    \n",
    "    #train_score = np.round(np.sqrt(mean_squared_error(y_train, model.predict(X_train))), 15)\n",
    "    test_score = np.round(np.sqrt(mean_squared_error(y_val, model.predict(X_val))), 15)\n",
    "                  \n",
    "    print(f'TEST RMSE : {test_score}')\n",
    "                  \n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best trial: {'max_depth': 33, 'subsample': 0.2028128133863628, 'colsample_bytree': 0.3316256936017043, 'learning_rate': 0.007295415117417998, 'reg_lambda': 21.211226081349032, 'reg_alpha': 7.386690008287902, 'min_child_samples': 88, 'num_leaves': 200, 'max_bin': 859, 'cat_smooth': 100, 'cat_l2': 3.5709736612307674}\n"
     ]
    }
   ],
   "source": [
    "optimize = partial(objective, X=X_train, y=y_train)\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='minimize')\n",
    "study_lgbm.optimize(optimize, n_trials=300)\n",
    "\n",
    "best_trial = study_lgbm.best_trial.params\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(f'best trial: {best_trial}')\n",
    "# i have commented out the trials so as to cut short the notebook execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_final_iteration = np.array(preds_list_final_iterations[-1:]).mean(axis=0)\n",
    "submission = pd.DataFrame({'id':test.id,\n",
    "          'target':y_preds_final_iteration})\n",
    "submission.to_csv(f'..\\\\kaggle_data\\\\{dt_string}_AUTOML_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_ittr_range = 20\n",
    "preds_list_final_iterations =[]\n",
    "\n",
    "for fold_index in range(2, fold_ittr_range):\n",
    "    print(f'Current fold index {fold_index}')\n",
    "    split = KFold(n_splits=fold_index)\n",
    "    lgbm_params = {'max_depth': 33, 'subsample': 0.2028128133863628, 'colsample_bytree': 0.3316256936017043, 'learning_rate': 0.007295415117417998, 'reg_lambda': 21.211226081349032, 'reg_alpha': 7.386690008287902, 'min_child_samples': 88, 'num_leaves': 200, 'max_bin': 859, 'cat_smooth': 100, 'cat_l2': 3.5709736612307674,\n",
    "                'verbose':-1}\n",
    "    \n",
    "\n",
    "    preds_list_base = []\n",
    "    preds_list_final_iteration = []\n",
    "    preds_list_all = []\n",
    "\n",
    "    for train_idx, val_idx in tqdm(split.split(X_train)):\n",
    "        X_tr = X_train.iloc[train_idx]\n",
    "        X_val = X_train.iloc[val_idx]\n",
    "        y_tr = y_train.iloc[train_idx]\n",
    "        y_val = y_train.iloc[val_idx]\n",
    "\n",
    "        Model = LGBMRegressor(**lgbm_params).fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
    "                      eval_metric=['rmse'],\n",
    "                      early_stopping_rounds=250, \n",
    "                      categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                      #callbacks=[optuna.integration.LightGBMPruningCallback(trial, metric='rmse')],\n",
    "                      verbose=0)\n",
    "\n",
    "        preds_list_base.append(Model.predict(X_test))\n",
    "        preds_list_all.append(Model.predict(X_test))\n",
    "        print(f'RMSE for Base model is {np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))}')\n",
    "        first_rmse = np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))\n",
    "        params = lgbm_params.copy()\n",
    "\n",
    "        for i in range(1, 8):\n",
    "            if i >2:    \n",
    "\n",
    "                # reducing regularizing params if \n",
    "\n",
    "                params['reg_lambda'] *= 0.9\n",
    "                params['reg_alpha'] *= 0.9\n",
    "                params['num_leaves'] += 40\n",
    "\n",
    "            params['learning_rate'] = 0.003\n",
    "            Model = LGBMRegressor(**params).fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
    "                      eval_metric=['rmse'],\n",
    "                      early_stopping_rounds=200, \n",
    "                      categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                      #callbacks=[optuna.integration.LightGBMPruningCallback(trial, metric='rmse')],\n",
    "                      verbose=0,\n",
    "                      init_model=Model)\n",
    "\n",
    "            preds_list_all.append(Model.predict(X_test))\n",
    "            print(f'RMSE for Incremental trial {i} model is {np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))}')\n",
    "        last_rmse = np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))\n",
    "        print('',end='\\n\\n')\n",
    "        print(f'Improvement of : {first_rmse - last_rmse}')\n",
    "        print('-' * 100)\n",
    "        preds_list_final_iteration.append(Model.predict(X_test))\n",
    "    preds_list_final_iterations[len(preds_list_final_iterations):] = preds_list_final_iteration\n",
    "    dt_string = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "    np.save(f'..\\\\kaggle_data\\\\{dt_string}_FI{fold_index}_sub.npy', preds_list_final_iterations)\n",
    "    y_preds_final_iteration = np.array(preds_list_final_iterations).mean(axis=0)\n",
    "    submission = pd.DataFrame({'id':test.id,\n",
    "              'target':y_preds_final_iteration})\n",
    "    submission.to_csv(f'..\\\\kaggle_data\\\\{dt_string}_FI{fold_index}_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028568,
     "end_time": "2021-02-19T04:27:13.410908",
     "exception": false,
     "start_time": "2021-02-19T04:27:13.382340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5375.500553,
   "end_time": "2021-02-19T04:27:15.130226",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-19T02:57:39.629673",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
