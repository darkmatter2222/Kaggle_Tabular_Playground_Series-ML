{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "concrete-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.layers.experimental import preprocessing as PP\n",
    "import tensorflow as tf\n",
    "\n",
    "import kerastuner as kt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "overall-technique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881122</td>\n",
       "      <td>0.421650</td>\n",
       "      <td>0.741413</td>\n",
       "      <td>0.895799</td>\n",
       "      <td>0.802461</td>\n",
       "      <td>0.724417</td>\n",
       "      <td>0.701915</td>\n",
       "      <td>0.877618</td>\n",
       "      <td>0.719903</td>\n",
       "      <td>6.994023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440011</td>\n",
       "      <td>0.346230</td>\n",
       "      <td>0.278495</td>\n",
       "      <td>0.593413</td>\n",
       "      <td>0.546056</td>\n",
       "      <td>0.613252</td>\n",
       "      <td>0.741289</td>\n",
       "      <td>0.326679</td>\n",
       "      <td>0.808464</td>\n",
       "      <td>8.071256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914155</td>\n",
       "      <td>0.369602</td>\n",
       "      <td>0.832564</td>\n",
       "      <td>0.865620</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.264104</td>\n",
       "      <td>0.695561</td>\n",
       "      <td>0.869133</td>\n",
       "      <td>0.828352</td>\n",
       "      <td>5.760456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934138</td>\n",
       "      <td>0.578930</td>\n",
       "      <td>0.407313</td>\n",
       "      <td>0.868099</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>0.494269</td>\n",
       "      <td>0.698125</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.614766</td>\n",
       "      <td>7.806457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.705940</td>\n",
       "      <td>0.325193</td>\n",
       "      <td>0.440967</td>\n",
       "      <td>0.462146</td>\n",
       "      <td>0.724447</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.343457</td>\n",
       "      <td>0.297743</td>\n",
       "      <td>6.868974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      cat0      cat1  cat2      cat3      cat4      cat5  cat6      cat7  \\\n",
       "0   1  0.000000  0.034483   0.0  0.000000  0.034483  0.103448   0.0  0.137931   \n",
       "1   2  0.034483  0.000000   0.0  0.000000  0.034483  0.034483   0.0  0.137931   \n",
       "2   3  0.000000  0.000000   0.0  0.068966  0.034483  0.103448   0.0  0.034483   \n",
       "3   4  0.000000  0.000000   0.0  0.068966  0.034483  0.103448   0.0  0.137931   \n",
       "4   6  0.000000  0.034483   0.0  0.000000  0.034483  0.034483   0.0  0.137931   \n",
       "\n",
       "       cat8  ...     cont5     cont6     cont7     cont8     cont9    cont10  \\\n",
       "0  0.068966  ...  0.881122  0.421650  0.741413  0.895799  0.802461  0.724417   \n",
       "1  0.000000  ...  0.440011  0.346230  0.278495  0.593413  0.546056  0.613252   \n",
       "2  0.068966  ...  0.914155  0.369602  0.832564  0.865620  0.825251  0.264104   \n",
       "3  0.206897  ...  0.934138  0.578930  0.407313  0.868099  0.794402  0.494269   \n",
       "4  0.068966  ...  0.382600  0.705940  0.325193  0.440967  0.462146  0.724447   \n",
       "\n",
       "     cont11    cont12    cont13    target  \n",
       "0  0.701915  0.877618  0.719903  6.994023  \n",
       "1  0.741289  0.326679  0.808464  8.071256  \n",
       "2  0.695561  0.869133  0.828352  5.760456  \n",
       "3  0.698125  0.809799  0.614766  7.806457  \n",
       "4  0.683073  0.343457  0.297743  6.868974  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('..\\\\kaggle_data\\\\train.csv')\n",
    "\n",
    "alpha = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z' ]\n",
    "alpha_conversion = {}\n",
    "for index in range(0, len(alpha)):\n",
    "    alpha_conversion[alpha[index]] = index / 29\n",
    "alpha_conversion\n",
    "\n",
    "train_data['cat0'].replace(alpha_conversion, inplace=True)\n",
    "train_data['cat1'].replace(alpha_conversion, inplace=True)\n",
    "train_data['cat2'].replace(alpha_conversion, inplace=True)\n",
    "train_data['cat3'].replace(alpha_conversion, inplace=True)\n",
    "train_data['cat4'].replace(alpha_conversion, inplace=True)\n",
    "train_data['cat5'].replace(alpha_conversion, inplace=True)\n",
    "train_data['cat6'].replace(alpha_conversion, inplace=True)\n",
    "train_data['cat7'].replace(alpha_conversion, inplace=True)\n",
    "train_data['cat8'].replace(alpha_conversion, inplace=True)\n",
    "train_data['cat9'].replace(alpha_conversion, inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expected-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data = train_data.drop(['id','target'],axis=1)\n",
    "label_data = train_data[['target']]\n",
    "\n",
    "training_vector_data = vector_data\n",
    "training_label_data = label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "received-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizedataframe(df):\n",
    "    x = df.values  # returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled)\n",
    "    return df\n",
    "\n",
    "\n",
    "normalizer = PP.Normalization()\n",
    "normalizer.adapt(training_vector_data.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "liberal-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return tf.math.sqrt(tf.math.reduce_mean(tf.math.squared_difference(y_true, y_pred)))\n",
    "\n",
    "\n",
    "def model_builder(hp):\n",
    "    global normalizer\n",
    "\n",
    "    this_model = tf.keras.Sequential()\n",
    "    this_model.add(normalizer)\n",
    "\n",
    "    hp_layer_one_units = hp.Int('layer_one_units', min_value=2, max_value=16, step=1)\n",
    "    this_model.add(tf.keras.layers.Dense(units=hp_layer_one_units, activation='relu'))\n",
    "    hp_layer_two_units = hp.Int('layer_two_units', min_value=2, max_value=16, step=1)\n",
    "    this_model.add(tf.keras.layers.Dense(units=hp_layer_two_units, activation='relu'))\n",
    "\n",
    "    this_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4])\n",
    "    hp_momentum = hp.Int('momentum', min_value=1, max_value=9, step=1)\n",
    "\n",
    "    tf.keras.optimizers.SGD(learning_rate=hp_learning_rate, momentum=hp_momentum / 10)\n",
    "    this_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                       loss=root_mean_squared_error,\n",
    "                       metrics=['mean_squared_error', 'accuracy'])\n",
    "\n",
    "    return this_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "powerful-general",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 Complete [00h 04m 06s]\n",
      "val_loss: 0.862825334072113\n",
      "\n",
      "Best val_loss So Far: 0.859819769859314\n",
      "Total elapsed time: 01h 10m 54s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 7 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=2,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt9')\n",
    "\n",
    "tuner.search(training_vector_data.values, training_label_data.values, epochs=50,\n",
    "             validation_split=0.2)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=100)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('layer_one_units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "forbidden-firmware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 25s 3ms/step - loss: 1.7728 - mean_squared_error: 6.0885 - accuracy: 0.0000e+00 - val_loss: 0.8684 - val_mean_squared_error: 0.7634 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 24s 3ms/step - loss: 0.8711 - mean_squared_error: 0.7680 - accuracy: 0.0000e+00 - val_loss: 0.8685 - val_mean_squared_error: 0.7638 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 24s 3ms/step - loss: 0.8690 - mean_squared_error: 0.7644 - accuracy: 0.0000e+00 - val_loss: 0.8659 - val_mean_squared_error: 0.7597 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 24s 3ms/step - loss: 0.8663 - mean_squared_error: 0.7595 - accuracy: 0.0000e+00 - val_loss: 0.8652 - val_mean_squared_error: 0.7583 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 24s 3ms/step - loss: 0.8668 - mean_squared_error: 0.7604 - accuracy: 0.0000e+00 - val_loss: 0.8628 - val_mean_squared_error: 0.7540 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 24s 3ms/step - loss: 0.8665 - mean_squared_error: 0.7601 - accuracy: 0.0000e+00 - val_loss: 0.8627 - val_mean_squared_error: 0.7537 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 24s 3ms/step - loss: 0.8667 - mean_squared_error: 0.7605 - accuracy: 0.0000e+00 - val_loss: 0.8618 - val_mean_squared_error: 0.7523 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 24s 3ms/step - loss: 0.8653 - mean_squared_error: 0.7578 - accuracy: 0.0000e+00 - val_loss: 0.8639 - val_mean_squared_error: 0.7558 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 24s 3ms/step - loss: 0.8658 - mean_squared_error: 0.7589 - accuracy: 0.0000e+00 - val_loss: 0.8653 - val_mean_squared_error: 0.7579 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 24s 3ms/step - loss: 0.8643 - mean_squared_error: 0.7561 - accuracy: 0.0000e+00 - val_loss: 0.8615 - val_mean_squared_error: 0.7518 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(training_vector_data, training_label_data, epochs=10,\n",
    "          validation_split=0.2)\n",
    "model.save('Model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "changing-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('..\\\\kaggle_data\\\\test.csv')\n",
    "\n",
    "alpha = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z' ]\n",
    "alpha_conversion = {}\n",
    "for index in range(0, len(alpha)):\n",
    "    alpha_conversion[alpha[index]] = index / 29\n",
    "alpha_conversion\n",
    "\n",
    "test['cat0'].replace(alpha_conversion, inplace=True)\n",
    "test['cat1'].replace(alpha_conversion, inplace=True)\n",
    "test['cat2'].replace(alpha_conversion, inplace=True)\n",
    "test['cat3'].replace(alpha_conversion, inplace=True)\n",
    "test['cat4'].replace(alpha_conversion, inplace=True)\n",
    "test['cat5'].replace(alpha_conversion, inplace=True)\n",
    "test['cat6'].replace(alpha_conversion, inplace=True)\n",
    "test['cat7'].replace(alpha_conversion, inplace=True)\n",
    "test['cat8'].replace(alpha_conversion, inplace=True)\n",
    "test['cat9'].replace(alpha_conversion, inplace=True)\n",
    "test.head()\n",
    "\n",
    "vector_data = test.drop(['id'],axis=1)\n",
    "\n",
    "sub = pd.read_csv('..\\\\kaggle_data\\\\sample_submission.csv')\n",
    "predictions = model.predict(vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "commercial-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['target'] = predictions\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-illness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
